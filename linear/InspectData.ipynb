{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../jupyter_imports.py\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pynwb import NWBHDF5IO\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import correlate\n",
    "from scipy.io import loadmat, savemat\n",
    "from math import floor, ceil\n",
    "# Script to add the entire project directory structure to the python path\n",
    "import sys, os\n",
    "\n",
    "# Find the root directory of the nse project\n",
    "parent_path, current_dir = os.path.split(os.path.abspath('.'))\n",
    "while current_dir != 'analysis':\n",
    "\tparent_path, current_dir = os.path.split(parent_path)\n",
    "p = os.path.join(parent_path, current_dir)\n",
    "# Add analysis\n",
    "if p not in sys.path:\n",
    "\tsys.path.append(p)\n",
    "\n",
    "# And standard list of subdirectories\n",
    "for d in [\"linear\", \"prelim\", \"utils\", \"kerasmodels\"]:\n",
    "\tif 'p\\\\%s' % d not in sys.path:\n",
    "\t\tsys.path.append('p\\\\%s' % d)\n",
    "\n",
    "# Now import all the other stuff:\n",
    "from utils import preprocess\n",
    "from utils import process\n",
    "from utils import misc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ankit\\Miniconda3\\envs\\nse\\lib\\site-packages\\scipy\\signal\\_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "C:\\Users\\Ankit\\Miniconda3\\envs\\nse\\lib\\site-packages\\scipy\\signal\\signaltools.py:3463: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return y[sl]\n"
     ]
    }
   ],
   "source": [
    "x = loadmat('%s/HighGammaAllChannels10sMovingZ.mat' % misc.get_data_path())\n",
    "e105 = x['data'][:, 104]\n",
    "stim = loadmat('%s/DynRip.cchspct.6oct.100hz' % misc.get_data_path())\n",
    "stim, resp = preprocess.align(stim['spct'], e105)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = process.split_data(stim, resp, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---104.08921957015991 seconds---\n",
      "-0.004340415463969904\n"
     ]
    }
   ],
   "source": [
    "r = linear_models.ridge_regression(process.flatten_spct(p.train_stim), p.train_resp, process.flatten_spct(p.test_stim), p.test_resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from linear import linear_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'FormatData'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-19fd1084fb33>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkerasmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLeNet\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\nse\\analysis\\kerasmodels\\LeNet.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mFormatData\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mformat_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m#define the ConvNet\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'FormatData'"
     ]
    }
   ],
   "source": [
    "from kerasmodels import LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35553, 100, 50)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.train_stim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = np.arange(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "yy = 2 * xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.0)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pearsonr(xx, yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kerasmodels import LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ankit\\nse\\analysis\\kerasmodels\\LeNet.py:31: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(2, 2), strides=(2, 1), data_format=\"channels_first\")`\n",
      "  model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 1), dim_ordering = 'th'))\n",
      "C:\\Users\\Ankit\\nse\\analysis\\kerasmodels\\LeNet.py:33: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(50, kernel_size=3, padding=\"same\")`\n",
      "  model.add(Conv2D(50, kernel_size=3, border_mode=\"same\"))\n",
      "C:\\Users\\Ankit\\nse\\analysis\\kerasmodels\\LeNet.py:35: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(2, 2), strides=(2, 1), data_format=\"channels_first\")`\n",
      "  model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 1), dim_ordering = 'th'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 31286 samples, validate on 4267 samples\n",
      "Epoch 1/20\n",
      "31286/31286 [==============================] - 514s 16ms/step - loss: 1.2612 - acc: 0.0000e+00 - r2score: -0.7892 - val_loss: 0.7236 - val_acc: 0.0000e+00 - val_r2score: -0.0107\n",
      "Epoch 2/20\n",
      "31286/31286 [==============================] - 489s 16ms/step - loss: 0.7069 - acc: 0.0000e+00 - r2score: -0.0111 - val_loss: 0.7229 - val_acc: 0.0000e+00 - val_r2score: -0.0104\n",
      "Epoch 3/20\n",
      "31286/31286 [==============================] - 458s 15ms/step - loss: 0.7045 - acc: 0.0000e+00 - r2score: -0.0083 - val_loss: 0.7254 - val_acc: 0.0000e+00 - val_r2score: -0.0117\n",
      "Epoch 4/20\n",
      "31286/31286 [==============================] - 443s 14ms/step - loss: 0.7022 - acc: 0.0000e+00 - r2score: -0.0043 - val_loss: 0.7241 - val_acc: 0.0000e+00 - val_r2score: -0.0122\n",
      "Epoch 5/20\n",
      "31286/31286 [==============================] - 442s 14ms/step - loss: 0.6975 - acc: 0.0000e+00 - r2score: 0.0031 - val_loss: 0.7321 - val_acc: 0.0000e+00 - val_r2score: -0.0205\n",
      "Epoch 6/20\n",
      "31286/31286 [==============================] - 442s 14ms/step - loss: 0.6915 - acc: 0.0000e+00 - r2score: 0.0100 - val_loss: 0.7257 - val_acc: 0.0000e+00 - val_r2score: -0.0141\n",
      "Epoch 7/20\n",
      "31286/31286 [==============================] - 440s 14ms/step - loss: 0.6839 - acc: 0.0000e+00 - r2score: 0.0199 - val_loss: 0.7232 - val_acc: 0.0000e+00 - val_r2score: -0.0118\n",
      "Epoch 8/20\n",
      "31286/31286 [==============================] - 441s 14ms/step - loss: 0.6729 - acc: 0.0000e+00 - r2score: 0.0369 - val_loss: 0.7276 - val_acc: 0.0000e+00 - val_r2score: -0.0204\n",
      "Epoch 9/20\n",
      "31286/31286 [==============================] - 451s 14ms/step - loss: 0.6617 - acc: 0.0000e+00 - r2score: 0.0518 - val_loss: 0.7226 - val_acc: 0.0000e+00 - val_r2score: -0.0163\n",
      "Epoch 10/20\n",
      "31286/31286 [==============================] - 450s 14ms/step - loss: 0.6476 - acc: 0.0000e+00 - r2score: 0.0675 - val_loss: 0.7388 - val_acc: 0.0000e+00 - val_r2score: -0.0412\n",
      "Epoch 11/20\n",
      "31286/31286 [==============================] - 451s 14ms/step - loss: 0.6284 - acc: 0.0000e+00 - r2score: 0.0987 - val_loss: 0.7491 - val_acc: 0.0000e+00 - val_r2score: -0.0537\n",
      "Epoch 12/20\n",
      "31286/31286 [==============================] - 446s 14ms/step - loss: 0.6121 - acc: 0.0000e+00 - r2score: 0.1161 - val_loss: 0.7499 - val_acc: 0.0000e+00 - val_r2score: -0.0539\n",
      "Epoch 13/20\n",
      "31286/31286 [==============================] - 445s 14ms/step - loss: 0.5888 - acc: 0.0000e+00 - r2score: 0.1485 - val_loss: 0.7475 - val_acc: 0.0000e+00 - val_r2score: -0.0580\n",
      "Epoch 14/20\n",
      "31286/31286 [==============================] - 445s 14ms/step - loss: 0.5773 - acc: 0.0000e+00 - r2score: 0.1665 - val_loss: 0.7683 - val_acc: 0.0000e+00 - val_r2score: -0.0840\n",
      "Epoch 15/20\n",
      "31286/31286 [==============================] - 455s 15ms/step - loss: 0.5492 - acc: 0.0000e+00 - r2score: 0.2068 - val_loss: 0.7598 - val_acc: 0.0000e+00 - val_r2score: -0.0655\n",
      "Epoch 16/20\n",
      "31286/31286 [==============================] - 448s 14ms/step - loss: 0.5281 - acc: 0.0000e+00 - r2score: 0.2346 - val_loss: 0.7797 - val_acc: 0.0000e+00 - val_r2score: -0.0997\n",
      "Epoch 17/20\n",
      "31286/31286 [==============================] - 443s 14ms/step - loss: 0.4999 - acc: 0.0000e+00 - r2score: 0.2743 - val_loss: 0.7780 - val_acc: 0.0000e+00 - val_r2score: -0.0981\n",
      "Epoch 18/20\n",
      "31286/31286 [==============================] - 450s 14ms/step - loss: 0.4761 - acc: 0.0000e+00 - r2score: 0.3052 - val_loss: 0.7719 - val_acc: 0.0000e+00 - val_r2score: -0.0850\n",
      "Epoch 19/20\n",
      "31286/31286 [==============================] - 454s 15ms/step - loss: 0.4507 - acc: 0.0000e+00 - r2score: 0.3422 - val_loss: 0.7967 - val_acc: 0.0000e+00 - val_r2score: -0.1210\n",
      "Epoch 20/20\n",
      "31286/31286 [==============================] - 468s 15ms/step - loss: 0.4142 - acc: 0.0000e+00 - r2score: 0.3913 - val_loss: 0.8069 - val_acc: 0.0000e+00 - val_r2score: -0.1345\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input arrays should have the same number of samples as target arrays. Found 8889 input samples and 35553 target samples.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-8443aac73011>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mLeNet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_stim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_resp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_stim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_resp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\nse\\analysis\\kerasmodels\\LeNet.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(xtrain, ytrain, xtest, ytest)\u001b[0m\n\u001b[0;32m     91\u001b[0m \tverbose=VERBOSE, validation_split=VALIDATION_SPLIT)\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m         \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mytest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mVERBOSE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Test score:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\nse\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps)\u001b[0m\n\u001b[0;32m   1098\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1099\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m   1101\u001b[0m         \u001b[1;31m# Prepare inputs, delegate logic to `test_loop`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_uses_dynamic_learning_phase\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\nse\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    800\u001b[0m             ]\n\u001b[0;32m    801\u001b[0m             \u001b[1;31m# Check that all arrays have the same length.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 802\u001b[1;33m             \u001b[0mcheck_array_length_consistency\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    803\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_graph_network\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    804\u001b[0m                 \u001b[1;31m# Additional checks to avoid users mistakenly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\nse\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mcheck_array_length_consistency\u001b[1;34m(inputs, targets, weights)\u001b[0m\n\u001b[0;32m    234\u001b[0m                          \u001b[1;34m'the same number of samples as target arrays. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m                          \u001b[1;34m'Found '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' input samples '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 236\u001b[1;33m                          'and ' + str(list(set_y)[0]) + ' target samples.')\n\u001b[0m\u001b[0;32m    237\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset_w\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m         raise ValueError('All sample_weight arrays should have '\n",
      "\u001b[1;31mValueError\u001b[0m: Input arrays should have the same number of samples as target arrays. Found 8889 input samples and 35553 target samples."
     ]
    }
   ],
   "source": [
    "LeNet.run(p.train_stim, p.train_resp, p.test_stim, p._resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[1, 2, 3], [1, 2, 3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1, 2, 3],\n",
       "        [1, 2, 3]],\n",
       "\n",
       "       [[1, 2, 3],\n",
       "        [1, 2, 3]],\n",
       "\n",
       "       [[1, 2, 3],\n",
       "        [1, 2, 3]]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.tile(x, (3, 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x[np.newaxis, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2, 3)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.tile(x, (3, 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1, 2, 3],\n",
       "        [1, 2, 3]],\n",
       "\n",
       "       [[1, 2, 3],\n",
       "        [1, 2, 3]],\n",
       "\n",
       "       [[1, 2, 3],\n",
       "        [1, 2, 3]]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2, 3)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = misc.get_data_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'h' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-63-9262a05ccb17>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msavemat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'%s/nrc_strf1.mat'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdata_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'h'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'h' is not defined"
     ]
    }
   ],
   "source": [
    "savemat('%s/nrc_strf1.mat' % data_path, dict([('h', h)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
